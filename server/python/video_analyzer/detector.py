"""
FastAPI + MediaPipe Tasks ‚Äî API –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–æ–∑ **v3.1**
===========================================
* –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞ –≤ —Ä–µ–∂–∏–º–µ –ø–∞—É–∑—ã –≤–∏–¥–µ–æ
* –ê–∫—Ç–∏–≤–Ω–æ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ "–Ω–∞–π—Ç–∏ —Ç–∞–Ω—Ü–æ—Ä–∞"
* –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∫–ª–∏–∫–∞–µ—Ç –ø–æ –æ–±–ª–∞—Å—Ç–∏, –∫–æ–¥ –≤—ã–¥–µ–ª—è–µ—Ç —á–µ–ª–æ–≤–µ–∫–∞
"""

import asyncio
import base64
import itertools
import logging
import os
import time
import urllib.request
from pathlib import Path
from typing import Any, List, Dict, Tuple
import threading
import queue
from concurrent.futures import ThreadPoolExecutor
import functools
import hashlib
from collections import OrderedDict, deque
import math

import cv2
import numpy as np
from fastapi import FastAPI, File, UploadFile, Query, Response, Header
from fastapi.middleware.cors import CORSMiddleware
import psutil  # –î–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–∞–º—è—Ç–∏
from fastapi.responses import JSONResponse

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π TurboJPEG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    from turbojpeg import TurboJPEG, TJFLAG_FASTDCT

    _tj = TurboJPEG()

    def _encode_jpeg(img_bgr: np.ndarray, q: int) -> str:
        """–ë—ã—Å—Ç—Ä–æ–µ JPEG –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ base64 —á–µ—Ä–µ–∑ libjpeg‚Äëturbo."""
        return base64.b64encode(_tj.encode(img_bgr, quality=q, flags=TJFLAG_FASTDCT)).decode()

except ImportError:

    def _encode_jpeg(img_bgr: np.ndarray, q: int) -> str:
        ok, buf = cv2.imencode(".jpg", img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), q])
        if not ok:
            raise RuntimeError("cv2.imencode failed")
        return base64.b64encode(buf).decode()


def _encode_png(img_bgra: np.ndarray) -> str:
    ok, buf = cv2.imencode(".png", img_bgra, [cv2.IMWRITE_PNG_COMPRESSION, 3])  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∂–∞—Ç–∏—è PNG
    if not ok:
        raise RuntimeError("cv2.imencode(.png) failed")
    return base64.b64encode(buf).decode()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MediaPipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.python import solutions
from mediapipe.python.solutions import drawing_utils, pose
from mediapipe.framework.formats import landmark_pb2

# –ò–º–ø–æ—Ä—Ç —É—Ç–∏–ª–∏—Ç –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è –∏ –ø–æ–∑—ã
mp_drawing = drawing_utils
mp_pose = pose

# –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –≤ —Å–ª—É—á–∞–µ –∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
try:
    from config.settings import (
        POSE_MODEL, POSE_DELEGATE, TARGET_SIDE, MAX_RESIZE_SIDE,
        JPEG_Q, PNG_COMPRESSION, MODEL_DIR, LOG_LEVEL,
        NUM_WORKERS, CACHE_SIZE, MIN_FRAME_DIFF, USE_ETAG,
        MAX_MEMORY_PERCENT, DETECTION_THRESHOLD
    )
except ImportError:
    # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    POSE_MODEL = os.getenv("POSE_MODEL", "lite")
    POSE_DELEGATE = os.getenv("POSE_DELEGATE", "gpu").lower()  # gpu | cpu
    TARGET_SIDE = int(os.getenv("TARGET_SIDE", "160"))
    MAX_RESIZE_SIDE = int(os.getenv("MAX_RESIZE_SIDE", "640"))
    JPEG_Q = int(os.getenv("JPEG_Q", "70"))
    PNG_COMPRESSION = int(os.getenv("PNG_COMPRESSION", "3"))
    MODEL_DIR = Path(os.getenv("MODEL_DIR", ".models"))
    LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
    NUM_WORKERS = int(os.getenv("NUM_WORKERS", "2"))
    CACHE_SIZE = int(os.getenv("CACHE_SIZE", "200"))
    MIN_FRAME_DIFF = float(os.getenv("MIN_FRAME_DIFF", "0.05"))
    USE_ETAG = os.getenv("USE_ETAG", "1") == "1"
    MAX_MEMORY_PERCENT = float(os.getenv("MAX_MEMORY_PERCENT", "80"))
    DETECTION_THRESHOLD = float(os.getenv("DETECTION_THRESHOLD", "0.05"))

# ----------------------------------------------------------------------------
# –ü—É–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –æ—á–µ—Ä–µ–¥—å
# ----------------------------------------------------------------------------
frame_queue = queue.Queue(maxsize=30)  # –û—á–µ—Ä–µ–¥—å –¥–ª—è –∫–∞–¥—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
result_cache = {}  # –ö—ç—à –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
frame_cache = OrderedDict()  # LRU –∫—ç—à –¥–ª—è —Ö–µ—à–µ–π –∫–∞–¥—Ä–æ–≤ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
similarity_cache = {}  # –ö—ç—à –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏
performance_stats = {
    "processed_frames": 0,
    "cached_hits": 0,
    "processing_times": deque(maxlen=50),  # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –≤—Ä–µ–º–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏
    "memory_usage": deque(maxlen=10),      # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
}
pool = ThreadPoolExecutor(max_workers=NUM_WORKERS)

# –û–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å —á–∞—Å—Ç–æ—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
rate_limiter = {
    "last_cleared": time.time(),
    "requests": {},  # IP -> –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    "max_per_minute": 300,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É —Å –æ–¥–Ω–æ–≥–æ IP
}

logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("pose_api")

# –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è MediaPipe Pose - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
try:
    # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è MediaPipe
    from mediapipe.python.solutions.pose import POSE_CONNECTIONS as MP_POSE_CONNECTIONS
    POSE_CONNECTIONS = list(MP_POSE_CONNECTIONS)
    logger.info(f"Using standard MediaPipe POSE_CONNECTIONS: {len(POSE_CONNECTIONS)} connections")
except ImportError:
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à–∏
    POSE_CONNECTIONS = [
        # –õ–∏—Ü–æ
        (0, 1), (1, 2), (2, 3), (3, 7),
        (0, 4), (4, 5), (5, 6), (6, 8),
        # –¢–æ—Ä—Å  
        (9, 10),
        (11, 12), (11, 23), (12, 24), (23, 24),
        # –†—É–∫–∏
        (11, 13), (13, 15), (15, 17), (15, 19), (15, 21), (17, 19),
        (12, 14), (14, 16), (16, 18), (16, 20), (16, 22), (18, 20),
        # –ù–æ–≥–∏
        (23, 25), (25, 27), (27, 29), (29, 31), (27, 31),
        (24, 26), (26, 28), (28, 30), (30, 32), (28, 32)
    ]
    logger.info(f"Using custom POSE_CONNECTIONS: {len(POSE_CONNECTIONS)} connections")

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
def check_memory_usage():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ"""
    memory_percent = psutil.virtual_memory().percent
    performance_stats["memory_usage"].append(memory_percent)
    return memory_percent < MAX_MEMORY_PERCENT

# ----------------------------------------------------------------------------
# üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–æ–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è)
# ----------------------------------------------------------------------------
VARIANT_URL = {
    "lite":  "pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
    "full":  "pose_landmarker_full/float16/1/pose_landmarker_full.task",
    "heavy": "pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task",
}
BASE_URL = "https://storage.googleapis.com/mediapipe-models/pose_landmarker/"
MODEL_DIR.mkdir(exist_ok=True)
MODEL_PATH = MODEL_DIR / f"pose_landmarker_{POSE_MODEL}.task"
if not MODEL_PATH.exists():
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ %s‚Ä¶", POSE_MODEL)
    urllib.request.urlretrieve(BASE_URL + VARIANT_URL[POSE_MODEL], MODEL_PATH)
    logger.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ %s", MODEL_PATH)

# ----------------------------------------------------------------------------
# üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
# ----------------------------------------------------------------------------
_delegate = mp.tasks.BaseOptions.Delegate.GPU if POSE_DELEGATE == "gpu" else mp.tasks.BaseOptions.Delegate.CPU

# –°–æ–∑–¥–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –¥–ª—è –ø–æ—Ç–æ–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
thread_local = threading.local()

def _preprocess_image(frame_rgb: np.ndarray) -> np.ndarray:
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if frame_rgb.size == 0:
            logger.error("Empty image received in preprocessing")
            return frame_rgb
            
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        frame_rgb = cv2.convertScaleAbs(frame_rgb, alpha=1.0, beta=0)
        return frame_rgb
        
    except Exception as e:
        logger.error(f"Error in image preprocessing: {e}")
        return frame_rgb

def get_landmarker():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—è, –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –¥–ª—è –ø–æ—Ç–æ–∫–∞"""
    if not hasattr(thread_local, "landmarker"):
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π API MediaPipe Tasks –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–æ–∑
            base_options = python.BaseOptions(
                model_asset_path=str(MODEL_PATH),
                delegate=_delegate
            )
            options = python.vision.PoseLandmarkerOptions(
                base_options=base_options,
                running_mode=python.vision.RunningMode.IMAGE,
                num_poses=50,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 50 –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ª—é–¥–µ–π
                min_pose_detection_confidence=0.05,  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
                min_pose_presence_confidence=0.05,   # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è
                min_tracking_confidence=0.05,        # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
                output_segmentation_masks=False
            )
            thread_local.landmarker = python.vision.PoseLandmarker.create_from_options(options)
            logger.info(f"Created PoseLandmarker with max {options.num_poses} poses, detection confidence {options.min_pose_detection_confidence}")
        except Exception as e:
            logger.error(f"Failed to create PoseLandmarker: {e}")
            raise
    return thread_local.landmarker

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å
landmarker = get_landmarker()
logger.info("–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –≥–æ—Ç–æ–≤ (–º–æ–¥–µ–ª—å=%s, –¥–µ–ª–µ–≥–∞—Ç=%s)", POSE_MODEL, POSE_DELEGATE)

_timestamp_ms = itertools.count(0, 33)  # ~30 fps –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏

# –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –æ—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –≤ –∫—ç—à–µ –∏ –¥–∞–Ω–Ω—ã–µ –ø–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤
def _cleanup_task():
    while True:
        try:
            # –û—á–∏—â–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å —á–∞—Å—Ç–æ—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤
            now = time.time()
            if now - rate_limiter["last_cleared"] > 60:  # –û—á–∏—â–∞–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
                rate_limiter["requests"] = {}
                rate_limiter["last_cleared"] = now
                
            # –û—á–∏—â–∞–µ–º –∫—ç—à –∫–∞–¥—Ä–æ–≤, –µ—Å–ª–∏ –æ–Ω —Å—Ç–∞–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–º –∏–ª–∏ —É—Ä–æ–≤–µ–Ω—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤—ã—Å–æ–∫–∏–π
            memory_percent = psutil.virtual_memory().percent
            performance_stats["memory_usage"].append(memory_percent)
            
            # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤—ã—Å–æ–∫–æ–µ
            target_size = CACHE_SIZE
            if memory_percent > 70:
                target_size = int(CACHE_SIZE * 0.7)  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 70% –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞, –µ—Å–ª–∏ –ø–∞–º—è—Ç—å –≤—ã—Å–æ–∫–∞—è
            elif memory_percent > 60:
                target_size = int(CACHE_SIZE * 0.8)  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 80% –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞, –µ—Å–ª–∏ –ø–∞–º—è—Ç—å —É–º–µ—Ä–µ–Ω–Ω–∞—è
                
            while len(frame_cache) > target_size:
                frame_cache.popitem(last=False)
                
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –æ—á–∏—â–∞–µ–º –∫—ç—à —Å—Ö–æ–∂–µ—Å—Ç–∏
            if len(similarity_cache) > 1000:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
                similarity_cache.clear()
                
            time.sleep(30)  # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—á–∏—Å—Ç–∫—É –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
        except Exception as e:
            logger.error(f"Error in cleanup task: {e}")

# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –æ—á–∏—Å—Ç–∫–∏
cleanup_thread = threading.Thread(target=_cleanup_task, daemon=True)
cleanup_thread.start()

# ----------------------------------------------------------------------------
# üîç –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ----------------------------------------------------------------------------
def _compute_frame_hash(frame: np.ndarray, click_point=None) -> str:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à –¥–ª—è –∫–∞–¥—Ä–∞ –∏ —Ç–æ—á–∫–∏ –∫–ª–∏–∫–∞"""
    # –•–µ—à –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–π —è—Ä–∫–æ—Å—Ç–∏ –∏ —Ç–æ—á–∫–∏ –∫–ª–∏–∫–∞
    small = cv2.resize(frame, (32, 32))
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    click_str = f"{click_point}" if click_point else "no_click"
    return hashlib.md5(gray.tobytes() + click_str.encode()).hexdigest()

def _bgr_to_mp_image(frame_bgr: np.ndarray) -> mp.Image:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ OpenCV BGR –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ MediaPipe RGB"""
    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π API MediaPipe Tasks
        return mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)
    except (TypeError, AttributeError):
        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π MediaPipe
        return frame_rgb

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –≤–µ—Ä—Å–∏–∏ MediaPipe
def draw_landmarks_on_image(image, landmarks, connections, is_selected=False):
    """–û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –≤–µ—Ä—Å–∏—é MediaPipe"""
    # –í—ã–±–∏—Ä–∞–µ–º —Ü–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç–∞—Ç—É—Å–∞ –≤—ã–±–æ—Ä–∞
    has_alpha = len(image.shape) == 3 and image.shape[2] == 4
    color = (0, 255, 255, 255) if is_selected else (0, 255, 0, 255)  # –ñ–µ–ª—Ç—ã–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ, –∑–µ–ª–µ–Ω—ã–π –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    h, w = image.shape[:2]
    
    # –°–Ω–∞—á–∞–ª–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    landmark_points = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
    if isinstance(landmarks, list):
        # –ü—Ä—è–º–æ–π —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ (–Ω–æ–≤—ã–π API MediaPipe)
        if len(landmarks) > 0 and hasattr(landmarks[0], 'x') and hasattr(landmarks[0], 'y'):
            # –≠—Ç–æ —É–∂–µ —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
            landmark_points = landmarks
        else:
            # –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            logger.warning(f"Unexpected landmark format in list: {type(landmarks[0]) if landmarks else 'empty'}")
            return
    elif hasattr(landmarks, 'landmark'):
        # –û–±—ä–µ–∫—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–æ–º landmark (—Å—Ç–∞—Ä—ã–π API MediaPipe)
        landmark_points = landmarks.landmark
    else:
        logger.warning(f"Unknown landmark format: {type(landmarks)}")
        return
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–∏ –º—ã —Å—Ç–∞—Ä—É—é –∏–ª–∏ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é MediaPipe –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏
        if hasattr(mp_drawing, 'draw_landmarks') and isinstance(landmarks, landmark_pb2.NormalizedLandmarkList):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –æ—Ç—Ä–∏—Å–æ–≤–∫—É MediaPipe –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
            mp_drawing.draw_landmarks(
                image, landmarks, connections,
                mp_drawing.DrawingSpec(color=color[:3], thickness=5, circle_radius=5),
                mp_drawing.DrawingSpec(color=color[:3], thickness=4)
            )
            if has_alpha:
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –¥–ª—è –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                gray = cv2.cvtColor(image[:, :, :3], cv2.COLOR_BGR2GRAY)
                image[gray > 0, 3] = 255
        else:
            # –†—É—á–Ω–∞—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ –¥–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
            # –°–Ω–∞—á–∞–ª–∞ —Ä–∏—Å—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            if connections:
                for connection in connections:
                    if len(connection) != 2:
                        continue
                        
                    start_idx, end_idx = connection
                    
                    if start_idx >= len(landmark_points) or end_idx >= len(landmark_points):
                        continue
                    
                    start_point = (
                        int(landmark_points[start_idx].x * w), 
                        int(landmark_points[start_idx].y * h)
                    )
                    end_point = (
                        int(landmark_points[end_idx].x * w),
                        int(landmark_points[end_idx].y * h)
                    )
                    
                    if has_alpha:
                        cv2.line(image, start_point, end_point, color[:3], 4)
                        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –ª–∏–Ω–∏–∏ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–ª—å—Ñ–∞
                        mask = np.zeros((h, w), dtype=np.uint8)
                        cv2.line(mask, start_point, end_point, 255, 4)
                        image[mask > 0, 3] = 255
                    else:
                        cv2.line(image, start_point, end_point, color[:3], 4)
            
            # –ó–∞—Ç–µ–º —Ä–∏—Å—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
            for landmark in landmark_points:
                if not hasattr(landmark, 'x') or not hasattr(landmark, 'y'):
                    continue
                
                x, y = int(landmark.x * w), int(landmark.y * h)
                if has_alpha:
                    cv2.circle(image, (x, y), 10, color[:3], -1)
                    # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –∫—Ä—É–≥–∞ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–ª—å—Ñ–∞
                    mask = np.zeros((h, w), dtype=np.uint8)
                    cv2.circle(mask, (x, y), 10, 255, -1)
                    image[mask > 0, 3] = 255
                else:
                    cv2.circle(image, (x, y), 10, color[:3], -1)
    except Exception as e:
        logger.error(f"Error drawing landmarks: {e}")
        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        try:
            cv2.putText(image, "Error drawing landmarks", (int(w/2)-100, int(h/2)), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        except:
            pass

def _landmarks_to_json(lms) -> List[dict[str, float]]:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –≤ JSON-—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç MediaPipe Tasks API
    if hasattr(lms, '__iter__'):
        # –≠—Ç–æ –∏—Ç–µ—Ä–∏—Ä—É–µ–º—ã–π –æ–±—ä–µ–∫—Ç (NormalizedLandmarkList)
        return [{
            "x": lm.x, 
            "y": lm.y, 
            "z": lm.z, 
            "visibility": getattr(lm, 'visibility', 1.0)
        } for lm in lms]
    elif hasattr(lms, 'landmark'):
        # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç MediaPipe API
        return [{
            "x": lm.x, 
            "y": lm.y, 
            "z": lm.z, 
            "visibility": getattr(lm, 'visibility', 1.0)
        } for lm in lms.landmark]
    else:
        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç, –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞
        logger.warning(f"Unknown landmarks format: {type(lms)}")
        return []

def _add_performance_stat(processing_time: int):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    performance_stats["processing_times"].append(processing_time)
    performance_stats["processed_frames"] += 1

def _get_avg_processing_time() -> float:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∫–∞–¥—Ä–æ–≤"""
    if not performance_stats["processing_times"]:
        return 0.0
    return sum(performance_stats["processing_times"]) / len(performance_stats["processing_times"])

def _poses_are_similar(pose1, pose2, threshold=0.12):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è—é—Ç—Å—è –ª–∏ –¥–≤–µ –ø–æ–∑—ã –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏"""
    if not pose1 or not pose2:
        return False
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –±–æ–ª—å—à–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    key_points = [0, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]  # –Ω–æ—Å, –ø–ª–µ—á–∏, –ª–æ–∫—Ç–∏, –∑–∞–ø—è—Å—Ç—å—è, –±–µ–¥—Ä–∞, –∫–æ–ª–µ–Ω–∏, –ª–æ–¥—ã–∂–∫–∏
    total_distance = 0
    valid_points = 0
    
    min_len = min(len(pose1), len(pose2))
    
    for point_idx in key_points:
        if point_idx >= min_len:
            continue
            
        lm1 = pose1[point_idx]
        lm2 = pose2[point_idx]
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∏–¥–∏–º—ã–µ —Ç–æ—á–∫–∏
        vis1 = getattr(lm1, 'visibility', 1.0)
        vis2 = getattr(lm2, 'visibility', 1.0)
        
        if vis1 > 0.3 and vis2 > 0.3:  # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥ –≤–∏–¥–∏–º–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            dx = lm1.x - lm2.x
            dy = lm1.y - lm2.y
            total_distance += math.sqrt(dx*dx + dy*dy)
            valid_points += 1
    
    if valid_points < 3:  # –¢—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 3 –≤–∏–¥–∏–º—ã–µ —Ç–æ—á–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        return False
        
    avg_distance = total_distance / valid_points
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ü–µ–Ω—Ç—Ä—É –º–∞—Å—Å
    center1_x = sum(lm.x for lm in pose1) / len(pose1)
    center1_y = sum(lm.y for lm in pose1) / len(pose1)
    center2_x = sum(lm.x for lm in pose2) / len(pose2)
    center2_y = sum(lm.y for lm in pose2) / len(pose2)
    
    center_distance = math.sqrt((center1_x - center2_x)**2 + (center1_y - center2_y)**2)
    
    # –ü–æ–∑—ã —Å—á–∏—Ç–∞—é—Ç—Å—è –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏, –µ—Å–ª–∏ –∏ —Å—Ä–µ–¥–Ω—è—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫, –∏ –¥–∏—Å—Ç–∞–Ω—Ü–∏—è —Ü–µ–Ω—Ç—Ä–æ–≤ –º–∞–ª—ã
    return avg_distance < threshold and center_distance < threshold * 1.5

# ----------------------------------------------------------------------------
# üèÉ –û–±—Ä–∞–±–æ—Ç–∫–∞
# ----------------------------------------------------------------------------
def _process(frame: np.ndarray, draw: bool, ret_img: bool, overlay: bool, click_point=None) -> dict[str, Any]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–æ–∑"""
    t0 = time.time()
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –∫–∞–¥—Ä–∞
    original_h, original_w = frame.shape[:2]
    logger.info(f"Processing frame with shape: {frame.shape}, original click_point: {click_point}")
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —Ç–æ—á–∫—É –∫–ª–∏–∫–∞, –µ—Å–ª–∏ –æ–Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ (–∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)
    scaled_click_point = None
    if click_point:
        click_x, click_y = click_point
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–∫–∏ –∫–ª–∏–∫–∞ —É–∂–µ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        scaled_click_point = (click_x, click_y)
        logger.info(f"Using click point: ({click_x}, {click_y})")
    
    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏)
    if original_w > 640 or original_h > 360:
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Å—à—Ç–∞–±, —á—Ç–æ–±—ã –≤–ø–∏—Å–∞—Ç—å—Å—è –≤ 640x360, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
        scale = min(640 / original_w, 360 / original_h)
        new_w = int(original_w * scale)
        new_h = int(original_h * scale)
        frame_rgb = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (new_w, new_h))
        logger.info(f"Resized frame to: {new_w}x{new_h}")
    else:
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        new_w, new_h = original_w, original_h
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    h, w = new_h, new_w
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Ö–µ—à –∫–∞–¥—Ä–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    frame_hash = _compute_frame_hash(frame_rgb, scaled_click_point)
    if frame_hash in frame_cache:
        cached_result = frame_cache[frame_hash].copy()
        performance_stats["cached_hits"] += 1
        logger.info(f"Returning cached result with {len(cached_result.get('poses', []))} poses")
        return cached_result
    
    try:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—è –ø–æ–∑
        landmarker = get_landmarker()
        all_poses = []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –º–Ω–æ–≥–æ–º–∞—Å—à—Ç–∞–±–Ω—É—é –¥–µ—Ç–µ–∫—Ü–∏—é –¥–ª—è –≤–∏–¥–µ–æ
        scales = [1.0, 0.6, 0.8, 1.2, 1.4, 0.5, 1.6]  # –ë–æ–ª—å—à–µ –º–∞—Å—à—Ç–∞–±–æ–≤, –≤–∫–ª—é—á–∞—è –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ
        
        for scale_idx, scale in enumerate(scales):
            try:
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                if scale != 1.0:
                    scaled_h = int(h * scale)
                    scaled_w = int(w * scale)
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã –Ω–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ
                    if scaled_h < 60 or scaled_w < 60 or scaled_h > 1400 or scaled_w > 1400:
                        continue
                    scaled_frame_rgb = cv2.resize(frame_rgb, (scaled_w, scaled_h))
                else:
                    scaled_frame_rgb = frame_rgb
                    scaled_h, scaled_w = h, w
                
                # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
                processed_frame = _preprocess_image(scaled_frame_rgb)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ MediaPipe —Ñ–æ—Ä–º–∞—Ç
                mp_image = _bgr_to_mp_image(cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR))
                
                # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ–∑
                detection_result = landmarker.detect(mp_image)
                
                if detection_result.pose_landmarks:
                    logger.info(f"Scale {scale}: detected {len(detection_result.pose_landmarks)} poses")
                    
                    # MediaPipe –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã [0,1] –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    # –≠—Ç–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —É–∂–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
                    for pose_landmarks in detection_result.pose_landmarks:
                        # –ü—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º landmarks –∫–∞–∫ –µ—Å—Ç—å - –æ–Ω–∏ —É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã
                        all_poses.append(list(pose_landmarks))
                
            except Exception as e:
                logger.warning(f"Error processing scale {scale}: {e}")
                continue
        
        logger.info(f"Total detected {len(all_poses)} poses")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ–∑
        unique_poses = []
        for pose in all_poses:
            is_duplicate = False
            for existing_pose in unique_poses:
                if _poses_are_similar(pose, existing_pose, threshold=0.08):  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_poses.append(pose)
        
        pose_landmarks = unique_poses
        logger.info(f"After deduplication: {len(pose_landmarks)} unique poses")
        
    except Exception as e:
        logger.error(f"Error in pose detection: {e}")
        pose_landmarks = []
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–∑–∞—Ö
    poses_data = []
    num_poses = len(pose_landmarks) if pose_landmarks else 0
    logger.info(f"Detected {num_poses} poses")
    
    # –ï—Å–ª–∏ –ø–æ–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π –æ–≤–µ—Ä–ª–µ–π
    if not pose_landmarks and ret_img:
        res = {
            "poses": [],
            "frame_width": original_w,
            "frame_height": original_h,
            "num_poses": 0,
            "processing_time_ms": int((time.time() - t0) * 1000),
        }
        if overlay:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_out = np.zeros((original_h, original_w, 4), dtype=np.uint8)
            res["image"] = "data:image/png;base64," + _encode_png(img_out)
            logger.info(f"Added transparent PNG overlay with no poses")
        else:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            res["image"] = "data:image/jpeg;base64," + _encode_jpeg(frame, JPEG_Q)
        return res
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–æ–∑—ã –∏ –Ω–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à—É—é –∫ —Ç–æ—á–∫–µ –∫–ª–∏–∫–∞, –µ—Å–ª–∏ –æ–Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞
    closest_pose_idx = None
    min_distance = float('inf')
    closest_pose_score = 0
    
    for i, pose_landmark in enumerate(pose_landmarks):
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –≤ –±–æ–ª–µ–µ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        landmarks_data = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç MediaPipe Tasks API
        # pose_landmark —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
        for lm in pose_landmark:
            landmarks_data.append({
                "x": lm.x, 
                "y": lm.y, 
                "z": lm.z, 
                "visibility": getattr(lm, 'visibility', 1.0)
            })
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã
        if not landmarks_data:
            logger.warning(f"No landmarks data for pose {i}")
            continue
            
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö [0,1]
        x_coords = [lm["x"] for lm in landmarks_data]
        y_coords = [lm["y"] for lm in landmarks_data]
        x_min, x_max = min(x_coords), max(x_coords)
        y_min, y_max = min(y_coords), max(y_coords)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É –ø–æ–∑—ã
        center_x = (x_min + x_max) / 2
        center_y = (y_min + y_max) / 2
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –≤–∏–¥–∏–º–æ—Å—Ç—å –∫–∞–∫ –º–µ—Ç—Ä–∏–∫—É –∫–∞—á–µ—Å—Ç–≤–∞
        visibilities = [lm.get("visibility", 0) for lm in landmarks_data]
        avg_visibility = sum(visibilities) / len(visibilities) if visibilities else 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–∑–µ - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        pose_info = {
            "landmarks": landmarks_data,
            "bbox": {
                "x_min": x_min * original_w,
                "y_min": y_min * original_h,
                "x_max": x_max * original_w,
                "y_max": y_max * original_h,
                "width": (x_max - x_min) * original_w,
                "height": (y_max - y_min) * original_h,
                "center_x": center_x * original_w,
                "center_y": center_y * original_h,
            },
            "visibility_score": avg_visibility
        }
        
        poses_data.append(pose_info)
            
        # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ –∫–ª–∏–∫–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞, –≤—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —ç—Ç–æ–π –ø–æ–∑—ã
        if scaled_click_point:
            click_x, click_y = scaled_click_point
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ —Ç–æ—á–∫–∞ –∫–ª–∏–∫–∞ –≤–Ω—É—Ç—Ä–∏ bbox –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö
            bbox_x_min = x_min * original_w
            bbox_x_max = x_max * original_w
            bbox_y_min = y_min * original_h
            bbox_y_max = y_max * original_h
            
            is_inside_bbox = (
                bbox_x_min <= click_x <= bbox_x_max and 
                bbox_y_min <= click_y <= bbox_y_max
            )
            
            logger.info(f"Pose {i} bbox: ({bbox_x_min:.1f}, {bbox_y_min:.1f}) to ({bbox_x_max:.1f}, {bbox_y_max:.1f})")
            logger.info(f"Checking click ({click_x}, {click_y}) against pose {i}: inside_bbox={is_inside_bbox}")
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö
            center_x_px = center_x * original_w
            center_y_px = center_y * original_h
            dist_to_center = math.sqrt(
                (center_x_px - click_x) ** 2 + 
                (center_y_px - click_y) ** 2
            )
            
            # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à—É—é –≤–∏–¥–∏–º—É—é –∫–ª—é—á–µ–≤—É—é —Ç–æ—á–∫—É
            min_keypoint_dist = float('inf')
            for lm in landmarks_data:
                if lm["visibility"] > 0.5:  # –£—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∏–¥–∏–º—ã–µ —Ç–æ—á–∫–∏
                    lm_x_px = lm["x"] * original_w
                    lm_y_px = lm["y"] * original_h
                    lm_dist = math.sqrt(
                        (lm_x_px - click_x) ** 2 + 
                        (lm_y_px - click_y) ** 2
                    )
                    min_keypoint_dist = min(min_keypoint_dist, lm_dist)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
            pose_size = math.sqrt((bbox_x_max - bbox_x_min) ** 2 + (bbox_y_max - bbox_y_min) ** 2)
            pose_score = avg_visibility * (0.7 + pose_size / (original_w * original_h) * 0.3)
            
            if is_inside_bbox:
                # –ï—Å–ª–∏ –∫–ª–∏–∫ –≤–Ω—É—Ç—Ä–∏ bbox, —ç—Ç–æ—Ç —Ç–∞–Ω—Ü–æ—Ä —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º
                final_score = 0.1  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π score –¥–ª—è –∫–ª–∏–∫–æ–≤ –≤–Ω—É—Ç—Ä–∏ bbox
                logger.info(f"Click is inside bbox of pose {i}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—ã–±–æ—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–∞–Ω—Ü–æ—Ä –∏–ª–∏ —É –Ω–µ–≥–æ –ª—É—á—à–µ score
                if closest_pose_idx is None or pose_score > closest_pose_score:
                    closest_pose_idx = i
                    min_distance = final_score
                    closest_pose_score = pose_score
                    logger.info(f"Selected pose {i} (inside bbox) with score {pose_score:.3f}")
            else:
                # –î–ª—è –∫–ª–∏–∫–æ–≤ –≤–Ω–µ bbox –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
                final_score = min(dist_to_center, min_keypoint_dist) * (1.0 - pose_score * 0.5)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—ã–±–æ—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç —Ç–∞–Ω—Ü–æ—Ä–∞ —Å –∫–ª–∏–∫–æ–º –≤–Ω—É—Ç—Ä–∏ bbox
                if (closest_pose_idx is None or 
                    not poses_data[closest_pose_idx].get("is_click_inside", False)) and final_score < min_distance:
                    closest_pose_idx = i
                    min_distance = final_score
                    closest_pose_score = pose_score
                    logger.info(f"Selected pose {i} (outside bbox) with score {final_score:.3f}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∏–∫–µ –¥–ª—è —ç—Ç–æ–π –ø–æ–∑—ã
            pose_info.update({
                "is_click_inside": is_inside_bbox,
                "distance_to_center": dist_to_center,
                "min_keypoint_distance": min_keypoint_dist,
                "final_score": final_score,
                "pose_score": pose_score,
                "bbox_debug": {
                    "x_min": bbox_x_min,
                    "y_min": bbox_y_min,
                    "x_max": bbox_x_max,
                    "y_max": bbox_y_max,
                    "click": {"x": click_x, "y": click_y}
                }
            })
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    res = {
        "poses": poses_data,
        "frame_width": original_w,
        "frame_height": original_h,
        "num_poses": len(poses_data),
        "processing_time_ms": int((time.time() - t0) * 1000),
    }
    
    # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ –∫–ª–∏–∫–∞ –±—ã–ª–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞, –≤–∫–ª—é—á–∞–µ–º –±–ª–∏–∂–∞–π—à—É—é –ø–æ–∑—É
    if scaled_click_point and closest_pose_idx is not None:
        res["selected_pose_index"] = closest_pose_idx
        logger.info(f"Final selected pose: {closest_pose_idx}")
    elif scaled_click_point:
        logger.warning("No pose selected for click point")
    
    # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
    if (draw or overlay) and ret_img:
        logger.info(f"Drawing landmarks with draw={draw}, overlay={overlay}")
        logger.info(f"pose_landmarks length: {len(pose_landmarks) if pose_landmarks else 0}")
        logger.info(f"click_point: {scaled_click_point}, closest_pose_idx: {closest_pose_idx}")
        
        if overlay:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–µ –±–∞–∑–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ú–ò —Ä–∞–∑–º–µ—Ä–∞–º–∏
            img_out = np.zeros((original_h, original_w, 4), dtype=np.uint8)
            logger.info(f"Created transparent image with original shape: {img_out.shape}")
            
            if pose_landmarks and len(pose_landmarks) > 0:
                logger.info("About to draw poses...")
                # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–æ–∑—É, –µ—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å —Ç–æ—á–∫–∞ –∫–ª–∏–∫–∞
                if scaled_click_point is not None and closest_pose_idx is not None:
                    # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–æ–∑—É
                    logger.info(f"Drawing selected pose {closest_pose_idx}")
                    pose_landmark = pose_landmarks[closest_pose_idx]
                    draw_landmarks_on_image(img_out, pose_landmark, POSE_CONNECTIONS, True)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–æ—á–∫–∏ –∫–ª–∏–∫–∞, –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –≤—Å–µ –ø–æ–∑—ã
                    logger.info(f"Drawing all {len(pose_landmarks)} poses")
                    for i, pose_landmark in enumerate(pose_landmarks):
                        logger.info(f"Drawing pose {i}")
                        draw_landmarks_on_image(img_out, pose_landmark, POSE_CONNECTIONS, False)
            else:
                logger.warning("No pose landmarks to draw!")
            
            res["image"] = "data:image/png;base64," + _encode_png(img_out)
            logger.info(f"Added transparent PNG overlay with {len(pose_landmarks)} poses")
        else:
            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
            img_out = frame.copy()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π BGR –∫–∞–¥—Ä
            if pose_landmarks and len(pose_landmarks) > 0:
                if scaled_click_point is not None and closest_pose_idx is not None:
                    # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–æ–∑—É
                    pose_landmark = pose_landmarks[closest_pose_idx]
                    draw_landmarks_on_image(img_out, pose_landmark, POSE_CONNECTIONS, True)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–æ—á–∫–∏ –∫–ª–∏–∫–∞, –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –≤—Å–µ –ø–æ–∑—ã
                    for i, pose_landmark in enumerate(pose_landmarks):
                        draw_landmarks_on_image(img_out, pose_landmark, POSE_CONNECTIONS, False)
            
            res["image"] = "data:image/jpeg;base64," + _encode_jpeg(img_out, JPEG_Q)
            logger.info(f"Added JPEG image with {len(pose_landmarks)} poses")
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∫—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    _add_performance_stat(res["processing_time_ms"])
    frame_cache[frame_hash] = res
    
    logger.info(f"Returning result with {len(poses_data)} poses, selected_index={res.get('selected_pose_index')}")
    return res

# ----------------------------------------------------------------------------
# üåê FastAPI
# ----------------------------------------------------------------------------
app = FastAPI(title="Dancer Detector API")

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ - –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/process-frame")
async def process_frame(
    file: UploadFile = File(...),
    image: int = Query(1, description="–í–æ–∑–≤—Ä–∞—â–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 0/1"),
    draw: int = Query(1, description="–û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ 0/1"),
    overlay: int = Query(1, description="–í–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–∫–µ–ª–µ—Ç PNG —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é 0/1"),
    resize: int = Query(1, description="–ò–∑–º–µ–Ω—è—Ç—å —Ä–∞–∑–º–µ—Ä –±–æ–ª—å—à–∏—Ö –∫–∞–¥—Ä–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ 0/1"),
    click_x: int = Query(None, description="X –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Ç–æ—á–∫–∏ –∫–ª–∏–∫–∞"),
    click_y: int = Query(None, description="Y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Ç–æ—á–∫–∏ –∫–ª–∏–∫–∞"),
    x_forwarded_for: str = Header(None),
):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –≤–∏–¥–µ–æ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–æ–∑"""
    response = Response()
    
    logger.info(f"Received request: click_x={click_x}, click_y={click_y}, image={image}, draw={draw}, overlay={overlay}")
    
    # –ü—Ä–æ—Å—Ç–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ IP
    client_ip = x_forwarded_for or "unknown"
    current_time = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–µ–ª–∞–µ—Ç –ª–∏ —ç—Ç–æ—Ç IP —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤
    if client_ip in rate_limiter["requests"]:
        request_count = rate_limiter["requests"][client_ip]
        if request_count > rate_limiter["max_per_minute"]:
            logger.warning(f"Rate limit exceeded for IP: {client_ip}")
            return JSONResponse(
                status_code=429,
                content={"error": "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."}
            )
        rate_limiter["requests"][client_ip] += 1
    else:
        rate_limiter["requests"][client_ip] = 1
    
    try:
        # –ß–∏—Ç–∞–µ–º –∫–∞–¥—Ä –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        contents = await file.read()
        logger.info(f"Read {len(contents)} bytes from uploaded file")
        logger.info(f"Content type: {file.content_type}, filename: {file.filename}")
        
        nparr = np.frombuffer(contents, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            logger.error("Failed to decode image data")
            return JSONResponse(
                status_code=400,
                content={"error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"}
            )
            
        logger.info(f"Decoded image with shape: {frame.shape}, dtype: {frame.dtype}, range: [{frame.min()}, {frame.max()}]")
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–º–µ–µ—Ç 3 –∫–∞–Ω–∞–ª–∞ (BGR)
        if len(frame.shape) != 3 or frame.shape[2] != 3:
            logger.warning(f"Image has wrong number of channels: {frame.shape}")
            
            # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–º–µ–µ—Ç 4 –∫–∞–Ω–∞–ª–∞ (BGRA), –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR
            if len(frame.shape) == 3 and frame.shape[2] == 4:
                logger.info("Converting BGRA to BGR")
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
            # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç—Ç–µ–Ω–∫–∞—Ö —Å–µ—Ä–æ–≥–æ, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR
            elif len(frame.shape) == 2 or (len(frame.shape) == 3 and frame.shape[2] == 1):
                logger.info("Converting grayscale to BGR")
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            else:
                logger.error(f"Unsupported image format with shape {frame.shape}")
                return JSONResponse(
                    status_code=400,
                    content={"error": "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å RGB –∏–ª–∏ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ."}
                )
                
            logger.info(f"After conversion, image shape: {frame.shape}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–¥—Ä —Å —Ç–æ—á–∫–æ–π –∫–ª–∏–∫–∞ –∏–ª–∏ –±–µ–∑ –Ω–µ–µ
        click_point = None
        if click_x is not None and click_y is not None:
            click_point = (click_x, click_y)
            logger.info(f"Processing frame with click_point: ({click_x}, {click_y})")
            
        result = _process(
            frame=frame,
            draw=bool(draw),
            ret_img=bool(image),
            overlay=bool(overlay),
            click_point=click_point
        )
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ ETag –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if USE_ETAG:
            result_hash = hashlib.md5(str(result).encode()).hexdigest()
            response.headers["ETag"] = f'W/"{result_hash}"'
            
        logger.info(f"Returning result with {len(result.get('poses', []))} poses")
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"Error processing frame: {str(e)}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"}
        )

@app.get("/health")
async def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
    avg_time = _get_avg_processing_time()
    memory_usage = psutil.virtual_memory().percent
    
    return {
        "status": "ok",
        "memory_usage_percent": memory_usage,
        "avg_processing_time_ms": avg_time,
        "processed_frames": performance_stats["processed_frames"],
        "cached_hits": performance_stats["cached_hits"],
        "model": POSE_MODEL,
        "delegate": POSE_DELEGATE,
    }

@app.get("/clear-cache")
async def clear_cache():
    """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫—ç—à–µ–π"""
    frame_cache.clear()
    similarity_cache.clear()
    return {"status": "ok", "message": "–ö—ç—à —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω"}
